{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - √âvaluation du Pipeline Anti-Fuite de Donn√©es\n",
    "\n",
    "Ce notebook d√©montre le workflow correct pour entra√Æner et √©valuer un mod√®le de classification de CV **sans fuite de donn√©es**.\n",
    "\n",
    "## Principe Cl√©\n",
    "\n",
    "```\n",
    "‚ùå MAUVAIS: Preprocessing ‚Üí Split ‚Üí Train/Test\n",
    "‚úÖ BON:     Split ‚Üí Preprocessing ‚Üí Train/Test\n",
    "```\n",
    "\n",
    "Le split doit √™tre fait sur les donn√©es **BRUTES** avant toute transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports et Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ajouter le dossier src au path\n",
    "PROJECT_ROOT = Path().absolute().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
    "\n",
    "print(f\"Projet: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Nos modules\n",
    "from training.data_splitter import DataSplitter\n",
    "from training.pipeline_builder import CVClassifierPipelineBuilder\n",
    "from training.trainer import CVClassifierTrainer\n",
    "from training.evaluator import PipelineEvaluator\n",
    "\n",
    "print(\"‚úì Modules import√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des Donn√©es Brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset BRUT (non pr√©process√©)\n",
    "DATA_PATH = PROJECT_ROOT / 'data' / 'raw' / 'resume_dataset.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"Dataset charg√©: {len(df)} CVs\")\n",
    "print(f\"Colonnes: {list(df.columns)}\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des cat√©gories\n",
    "print(\"Distribution des cat√©gories:\")\n",
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split des Donn√©es BRUTES (√âtape Critique)\n",
    "\n",
    "‚ö†Ô∏è **C'est ici que tout se joue !**\n",
    "\n",
    "On s√©pare les donn√©es **AVANT** tout preprocessing pour √©viter la fuite d'information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le splitter\n",
    "splitter = DataSplitter(\n",
    "    test_size=0.2,      # 20% pour le test\n",
    "    random_state=42,    # Reproductibilit√©\n",
    "    stratify=True       # Garder la distribution des classes\n",
    ")\n",
    "\n",
    "# Dossier pour sauvegarder les indices\n",
    "SPLIT_DIR = PROJECT_ROOT / 'data' / 'splits'\n",
    "\n",
    "# V√©rifier si un split existe d√©j√†\n",
    "if splitter.split_exists(SPLIT_DIR):\n",
    "    print(\"Split existant trouv√©, chargement...\")\n",
    "    train_df, test_df = splitter.load_split(df, SPLIT_DIR)\n",
    "else:\n",
    "    print(\"Cr√©ation d'un nouveau split...\")\n",
    "    train_df, test_df = splitter.split_and_save(df, 'Category', SPLIT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rifier le split\n",
    "print(f\"\\nüìä R√©sum√© du Split:\")\n",
    "print(f\"   Train: {len(train_df)} CVs ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"   Test:  {len(test_df)} CVs ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"   Total: {len(df)} CVs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire X et y\n",
    "X_train = train_df['Resume'].values  # Texte BRUT\n",
    "y_train = train_df['Category'].values\n",
    "\n",
    "X_test = test_df['Resume'].values    # Texte BRUT\n",
    "y_test = test_df['Category'].values\n",
    "\n",
    "print(f\"X_train: {len(X_train)} textes bruts\")\n",
    "print(f\"X_test:  {len(X_test)} textes bruts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Encodage des Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder les cat√©gories\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(f\"Nombre de classes: {len(label_encoder.classes_)}\")\n",
    "print(f\"Classes: {list(label_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Construction du Pipeline\n",
    "\n",
    "Le pipeline encapsule toutes les transformations:\n",
    "\n",
    "```\n",
    "Texte Brut ‚Üí TextCleanerTransformer ‚Üí TfidfVectorizer ‚Üí Classifier\n",
    "```\n",
    "\n",
    "Ainsi, le TF-IDF est **fit uniquement sur les donn√©es d'entra√Ænement**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le pipeline\n",
    "builder = CVClassifierPipelineBuilder(\n",
    "    classifier_name='random_forest',\n",
    "    tfidf_params={'max_features': 5000, 'ngram_range': (1, 2)},\n",
    "    classifier_params={'n_estimators': 200, 'random_state': 42}\n",
    ")\n",
    "\n",
    "pipeline = builder.build()\n",
    "\n",
    "print(\"Pipeline construit:\")\n",
    "for name, step in pipeline.steps:\n",
    "    print(f\"  ‚Üí {name}: {type(step).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation (sur Train uniquement)\n",
    "\n",
    "La cross-validation est effectu√©e **uniquement sur les donn√©es d'entra√Ænement**.\n",
    "\n",
    "Le test set reste compl√®tement isol√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er le trainer\n",
    "trainer = CVClassifierTrainer(\n",
    "    classifier_name='random_forest',\n",
    "    n_folds=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Lancer la cross-validation\n",
    "cv_results = trainer.cross_validate(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les r√©sultats de CV\n",
    "print(\"\\nüìà R√©sultats Cross-Validation (5-fold):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for metric, scores in cv_results['scores'].items():\n",
    "    print(f\"\\n{metric}:\")\n",
    "    print(f\"  CV Mean:  {scores['cv_mean']:.4f} (+/- {scores['cv_std']:.4f})\")\n",
    "    print(f\"  Train:    {scores['train_mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entra√Ænement du Mod√®le Final\n",
    "\n",
    "On entra√Æne maintenant le pipeline sur **tout** le train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entra√Æner le mod√®le final\n",
    "pipeline = trainer.train(X_train, y_train_encoded, label_encoder)\n",
    "\n",
    "print(f\"\\n‚úì Mod√®le entra√Æn√© en {trainer.training_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. √âvaluation Finale sur le Test Set\n",
    "\n",
    "‚ö†Ô∏è **Cette √©tape ne doit √™tre faite qu'UNE SEULE FOIS**, √† la toute fin.\n",
    "\n",
    "Le test set n'a jamais √©t√© vu pendant l'entra√Ænement ou la validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er l'√©valuateur\n",
    "evaluator = PipelineEvaluator(pipeline, label_encoder)\n",
    "\n",
    "# √âvaluer sur le test set\n",
    "test_results = evaluator.evaluate(X_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer CV vs Test\n",
    "comparison = evaluator.compare_with_cv(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Analyse des R√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau r√©capitulatif\n",
    "import pandas as pd\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'M√©trique': ['Accuracy', 'F1 Macro', 'Precision', 'Recall'],\n",
    "    'CV (mean)': [\n",
    "        cv_results['scores']['accuracy']['cv_mean'],\n",
    "        cv_results['scores']['f1_macro']['cv_mean'],\n",
    "        cv_results['scores']['precision_macro']['cv_mean'],\n",
    "        cv_results['scores']['recall_macro']['cv_mean']\n",
    "    ],\n",
    "    'CV (std)': [\n",
    "        cv_results['scores']['accuracy']['cv_std'],\n",
    "        cv_results['scores']['f1_macro']['cv_std'],\n",
    "        cv_results['scores']['precision_macro']['cv_std'],\n",
    "        cv_results['scores']['recall_macro']['cv_std']\n",
    "    ],\n",
    "    'Test': [\n",
    "        test_results['metrics']['accuracy'],\n",
    "        test_results['metrics']['f1_macro'],\n",
    "        test_results['metrics']['precision_macro'],\n",
    "        test_results['metrics']['recall_macro']\n",
    "    ]\n",
    "})\n",
    "\n",
    "summary['CV (mean)'] = summary['CV (mean)'].apply(lambda x: f\"{x:.4f}\")\n",
    "summary['CV (std)'] = summary['CV (std)'].apply(lambda x: f\"¬±{x:.4f}\")\n",
    "summary['Test'] = summary['Test'].apply(lambda x: f\"{x:.4f}\")\n",
    "\n",
    "print(\"\\nüìä Tableau R√©capitulatif:\")\n",
    "print(\"=\" * 60)\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la matrice de confusion\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = np.array(test_results['confusion_matrix']['matrix'])\n",
    "labels = test_results['confusion_matrix']['labels']\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Matrice de Confusion - Test Set')\n",
    "plt.xlabel('Pr√©dit')\n",
    "plt.ylabel('R√©el')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test avec un Nouveau CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de pr√©diction\n",
    "exemple_cv = \"\"\"\n",
    "John Doe\n",
    "Senior Software Developer\n",
    "\n",
    "EXPERIENCE:\n",
    "- 5 years of Java development\n",
    "- Spring Boot, Microservices, REST APIs\n",
    "- Docker, Kubernetes, AWS\n",
    "- Agile methodologies, Scrum\n",
    "\n",
    "SKILLS:\n",
    "Java, Python, SQL, MongoDB, Git, Jenkins, CI/CD\n",
    "\n",
    "EDUCATION:\n",
    "Master's in Computer Science\n",
    "\"\"\"\n",
    "\n",
    "# Pr√©diction (le pipeline g√®re tout: nettoyage + vectorisation + pr√©diction)\n",
    "prediction = pipeline.predict([exemple_cv])[0]\n",
    "probabilities = pipeline.predict_proba([exemple_cv])[0]\n",
    "\n",
    "# D√©coder\n",
    "category = label_encoder.inverse_transform([prediction])[0]\n",
    "confidence = probabilities.max()\n",
    "\n",
    "print(f\"Cat√©gorie pr√©dite: {category}\")\n",
    "print(f\"Confiance: {confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 cat√©gories\n",
    "top5_idx = np.argsort(probabilities)[::-1][:5]\n",
    "\n",
    "print(\"\\nTop 5 cat√©gories:\")\n",
    "for i, idx in enumerate(top5_idx, 1):\n",
    "    cat = label_encoder.inverse_transform([idx])[0]\n",
    "    prob = probabilities[idx]\n",
    "    print(f\"  {i}. {cat}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "### Points Cl√©s\n",
    "\n",
    "1. **Split AVANT preprocessing**: Les donn√©es sont s√©par√©es en train/test sur le texte BRUT\n",
    "2. **Pipeline sklearn**: Toutes les transformations sont encapsul√©es\n",
    "3. **Cross-validation sur train uniquement**: Le test set reste isol√©\n",
    "4. **√âvaluation unique**: Le test set n'est utilis√© qu'une seule fois √† la fin\n",
    "\n",
    "### V√©rification Anti-Leakage\n",
    "\n",
    "Si les scores CV et Test sont **proches**, c'est un bon signe qu'il n'y a pas de fuite de donn√©es.\n",
    "\n",
    "- ‚úÖ Diff√©rence < 5%: OK\n",
    "- ‚ö†Ô∏è Diff√©rence > 10%: Possible overfitting ou leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification finale\n",
    "diff = abs(comparison['cv_accuracy'] - comparison['test_accuracy'])\n",
    "\n",
    "print(\"\\nüîç V√©rification Anti-Leakage:\")\n",
    "print(f\"   CV Accuracy:   {comparison['cv_accuracy']:.4f}\")\n",
    "print(f\"   Test Accuracy: {comparison['test_accuracy']:.4f}\")\n",
    "print(f\"   Diff√©rence:    {diff:.4f}\")\n",
    "\n",
    "if diff < 0.05:\n",
    "    print(\"\\n‚úÖ Pas de fuite de donn√©es d√©tect√©e!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Attention: √©cart important entre CV et Test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
